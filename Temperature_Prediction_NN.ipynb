{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 486.0816 - mae: 21.0695 - val_loss: 423.9676 - val_mae: 19.4540\n",
      "Epoch 2/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 470.9853 - mae: 20.7481 - val_loss: 405.6366 - val_mae: 18.9711\n",
      "Epoch 3/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 422.3861 - mae: 19.5587 - val_loss: 371.4385 - val_mae: 18.0358\n",
      "Epoch 4/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 405.2500 - mae: 19.0653 - val_loss: 303.6087 - val_mae: 16.0226\n",
      "Epoch 5/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 312.5654 - mae: 16.4490 - val_loss: 189.6057 - val_mae: 11.9126\n",
      "Epoch 6/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 176.9202 - mae: 11.7556 - val_loss: 72.8433 - val_mae: 6.8191\n",
      "Epoch 7/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 68.6881 - mae: 6.7245 - val_loss: 72.9765 - val_mae: 7.3709\n",
      "Epoch 8/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 52.6723 - mae: 5.8224 - val_loss: 65.3079 - val_mae: 7.0414\n",
      "Epoch 9/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 43.5692 - mae: 5.1898 - val_loss: 54.8156 - val_mae: 6.3201\n",
      "Epoch 10/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 48.9023 - mae: 5.6333 - val_loss: 54.3611 - val_mae: 6.3698\n",
      "Epoch 11/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 39.1411 - mae: 4.8587 - val_loss: 56.2117 - val_mae: 6.5421\n",
      "Epoch 12/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 43.6124 - mae: 5.2731 - val_loss: 56.0990 - val_mae: 6.5233\n",
      "Epoch 13/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 41.9151 - mae: 5.1045 - val_loss: 52.2851 - val_mae: 6.2454\n",
      "Epoch 14/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 46.1320 - mae: 5.3807 - val_loss: 52.3584 - val_mae: 6.2637\n",
      "Epoch 15/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 40.5874 - mae: 4.9653 - val_loss: 53.3926 - val_mae: 6.3106\n",
      "Epoch 16/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 41.3133 - mae: 5.1662 - val_loss: 50.4810 - val_mae: 6.1225\n",
      "Epoch 17/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 39.6351 - mae: 4.8641 - val_loss: 50.4727 - val_mae: 6.1059\n",
      "Epoch 18/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 43.1954 - mae: 5.0591 - val_loss: 49.5303 - val_mae: 6.0386\n",
      "Epoch 19/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 41.9866 - mae: 5.1409 - val_loss: 48.3573 - val_mae: 5.9612\n",
      "Epoch 20/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 43.4240 - mae: 5.1741 - val_loss: 47.5176 - val_mae: 5.9047\n",
      "Epoch 21/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 41.1380 - mae: 5.0430 - val_loss: 47.0911 - val_mae: 5.8651\n",
      "Epoch 22/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 43.1707 - mae: 5.1946 - val_loss: 46.8318 - val_mae: 5.8329\n",
      "Epoch 23/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 41.5032 - mae: 5.0195 - val_loss: 44.7008 - val_mae: 5.7225\n",
      "Epoch 24/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 40.4157 - mae: 5.0130 - val_loss: 46.3477 - val_mae: 5.7706\n",
      "Epoch 25/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 44.7503 - mae: 5.2463 - val_loss: 45.5721 - val_mae: 5.7136\n",
      "Epoch 26/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 38.7286 - mae: 4.9577 - val_loss: 43.1400 - val_mae: 5.6003\n",
      "Epoch 27/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 38.4911 - mae: 4.8729 - val_loss: 43.8482 - val_mae: 5.6124\n",
      "Epoch 28/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 35.3011 - mae: 4.6406 - val_loss: 43.0052 - val_mae: 5.5593\n",
      "Epoch 29/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 35.3604 - mae: 4.5873 - val_loss: 42.4998 - val_mae: 5.5243\n",
      "Epoch 30/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 35.6832 - mae: 4.7874 - val_loss: 43.1819 - val_mae: 5.5402\n",
      "Epoch 31/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 38.5015 - mae: 4.8391 - val_loss: 42.1286 - val_mae: 5.4819\n",
      "Epoch 32/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 35.9426 - mae: 4.6568 - val_loss: 40.6110 - val_mae: 5.4027\n",
      "Epoch 33/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 35.3031 - mae: 4.7545 - val_loss: 42.1794 - val_mae: 5.4568\n",
      "Epoch 34/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 35.6136 - mae: 4.7468 - val_loss: 40.3653 - val_mae: 5.3868\n",
      "Epoch 35/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 33.8845 - mae: 4.5820 - val_loss: 41.5123 - val_mae: 5.4291\n",
      "Epoch 36/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 35.7962 - mae: 4.7383 - val_loss: 41.0440 - val_mae: 5.4107\n",
      "Epoch 37/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 33.3322 - mae: 4.5786 - val_loss: 41.3583 - val_mae: 5.4111\n",
      "Epoch 38/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 30.9804 - mae: 4.3179 - val_loss: 39.5215 - val_mae: 5.3278\n",
      "Epoch 39/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 33.2265 - mae: 4.4354 - val_loss: 38.4256 - val_mae: 5.2571\n",
      "Epoch 40/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 33.6157 - mae: 4.5821 - val_loss: 38.8158 - val_mae: 5.2541\n",
      "Epoch 41/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 32.4978 - mae: 4.5592 - val_loss: 37.7696 - val_mae: 5.1875\n",
      "Epoch 42/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 30.9798 - mae: 4.3222 - val_loss: 37.2088 - val_mae: 5.1352\n",
      "Epoch 43/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 31.3554 - mae: 4.4810 - val_loss: 36.8802 - val_mae: 5.0964\n",
      "Epoch 44/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 25.3988 - mae: 3.9173 - val_loss: 36.7256 - val_mae: 5.0735\n",
      "Epoch 45/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 32.3258 - mae: 4.5153 - val_loss: 34.7874 - val_mae: 4.9536\n",
      "Epoch 46/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 29.4399 - mae: 4.1822 - val_loss: 35.3254 - val_mae: 4.9789\n",
      "Epoch 47/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 29.3872 - mae: 4.2794 - val_loss: 34.0942 - val_mae: 4.8955\n",
      "Epoch 48/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 29.0810 - mae: 4.1358 - val_loss: 33.6211 - val_mae: 4.8472\n",
      "Epoch 49/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 31.6134 - mae: 4.3361 - val_loss: 33.0365 - val_mae: 4.8138\n",
      "Epoch 50/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 26.7006 - mae: 4.0567 - val_loss: 33.2198 - val_mae: 4.8187\n",
      "Epoch 51/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 33.4420 - mae: 4.5304 - val_loss: 32.3890 - val_mae: 4.7453\n",
      "Epoch 52/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 25.2359 - mae: 3.8115 - val_loss: 32.0491 - val_mae: 4.7087\n",
      "Epoch 53/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 25.8488 - mae: 3.9936 - val_loss: 31.0890 - val_mae: 4.6395\n",
      "Epoch 54/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 26.8442 - mae: 3.9625 - val_loss: 31.2813 - val_mae: 4.6173\n",
      "Epoch 55/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 26.1365 - mae: 3.9929 - val_loss: 29.1505 - val_mae: 4.4748\n",
      "Epoch 56/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 29.3552 - mae: 4.1113 - val_loss: 28.7580 - val_mae: 4.4121\n",
      "Epoch 57/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 21.7979 - mae: 3.6563 - val_loss: 29.1064 - val_mae: 4.4666\n",
      "Epoch 58/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 33.1967 - mae: 4.5031 - val_loss: 27.6252 - val_mae: 4.3121\n",
      "Epoch 59/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 21.6885 - mae: 3.6690 - val_loss: 27.5140 - val_mae: 4.2913\n",
      "Epoch 60/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 26.5476 - mae: 4.0340 - val_loss: 28.2318 - val_mae: 4.3416\n",
      "Epoch 61/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 26.4544 - mae: 4.0307 - val_loss: 26.4519 - val_mae: 4.2105\n",
      "Epoch 62/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 21.0332 - mae: 3.4822 - val_loss: 26.1440 - val_mae: 4.1599\n",
      "Epoch 63/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 26.7485 - mae: 3.9322 - val_loss: 26.4713 - val_mae: 4.1970\n",
      "Epoch 64/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 22.6653 - mae: 3.7597 - val_loss: 24.8490 - val_mae: 4.0425\n",
      "Epoch 65/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 23.1260 - mae: 3.7046 - val_loss: 25.1060 - val_mae: 4.0618\n",
      "Epoch 66/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 22.1542 - mae: 3.6915 - val_loss: 25.2169 - val_mae: 4.0406\n",
      "Epoch 67/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 22.6677 - mae: 3.7002 - val_loss: 24.6272 - val_mae: 3.9766\n",
      "Epoch 68/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 23.8696 - mae: 3.8539 - val_loss: 24.0421 - val_mae: 3.9299\n",
      "Epoch 69/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 22.8814 - mae: 3.7446 - val_loss: 23.9986 - val_mae: 3.9552\n",
      "Epoch 70/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 20.2936 - mae: 3.4939 - val_loss: 22.9949 - val_mae: 3.8573\n",
      "Epoch 71/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 20.8345 - mae: 3.4781 - val_loss: 22.7233 - val_mae: 3.8236\n",
      "Epoch 72/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 22.7319 - mae: 3.6760 - val_loss: 22.4736 - val_mae: 3.8090\n",
      "Epoch 73/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 23.4135 - mae: 3.7244 - val_loss: 22.7906 - val_mae: 3.8508\n",
      "Epoch 74/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 23.5802 - mae: 3.7286 - val_loss: 22.3352 - val_mae: 3.7852\n",
      "Epoch 75/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 19.2916 - mae: 3.3254 - val_loss: 22.5714 - val_mae: 3.8015\n",
      "Epoch 76/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 21.4210 - mae: 3.5367 - val_loss: 21.6461 - val_mae: 3.7260\n",
      "Epoch 77/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 19.9753 - mae: 3.5185 - val_loss: 21.8417 - val_mae: 3.7366\n",
      "Epoch 78/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 19.4386 - mae: 3.4493 - val_loss: 20.6280 - val_mae: 3.6433\n",
      "Epoch 79/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 18.7078 - mae: 3.2361 - val_loss: 20.9391 - val_mae: 3.6955\n",
      "Epoch 80/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 16.1727 - mae: 3.1018 - val_loss: 21.3590 - val_mae: 3.7038\n",
      "Epoch 81/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 19.9380 - mae: 3.3853 - val_loss: 20.7650 - val_mae: 3.6541\n",
      "Epoch 82/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 19.8931 - mae: 3.4264 - val_loss: 20.8516 - val_mae: 3.6543\n",
      "Epoch 83/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 18.4063 - mae: 3.3499 - val_loss: 20.3392 - val_mae: 3.6368\n",
      "Epoch 84/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 18.1155 - mae: 3.2031 - val_loss: 20.4804 - val_mae: 3.6377\n",
      "Epoch 85/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 18.4415 - mae: 3.1890 - val_loss: 19.7437 - val_mae: 3.5709\n",
      "Epoch 86/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 19.4742 - mae: 3.3039 - val_loss: 19.3872 - val_mae: 3.5445\n",
      "Epoch 87/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 17.0954 - mae: 3.2224 - val_loss: 19.1215 - val_mae: 3.5174\n",
      "Epoch 88/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 16.3509 - mae: 3.1137 - val_loss: 20.0321 - val_mae: 3.5735\n",
      "Epoch 89/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 19.3101 - mae: 3.4246 - val_loss: 20.0018 - val_mae: 3.5563\n",
      "Epoch 90/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 18.1592 - mae: 3.2451 - val_loss: 19.8672 - val_mae: 3.5479\n",
      "Epoch 91/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 18.9043 - mae: 3.3575 - val_loss: 18.9494 - val_mae: 3.4955\n",
      "Epoch 92/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 16.9173 - mae: 3.1966 - val_loss: 18.9043 - val_mae: 3.5077\n",
      "Epoch 93/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 21.0702 - mae: 3.4081 - val_loss: 18.8725 - val_mae: 3.4903\n",
      "Epoch 94/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 19.5204 - mae: 3.3712 - val_loss: 18.6491 - val_mae: 3.4959\n",
      "Epoch 95/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 18.4412 - mae: 3.4006 - val_loss: 18.2621 - val_mae: 3.4675\n",
      "Epoch 96/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 16.7772 - mae: 3.1527 - val_loss: 18.5530 - val_mae: 3.4635\n",
      "Epoch 97/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 18.2324 - mae: 3.2126 - val_loss: 18.5989 - val_mae: 3.4332\n",
      "Epoch 98/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 17.2430 - mae: 3.1311 - val_loss: 19.4492 - val_mae: 3.5108\n",
      "Epoch 99/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 15.2059 - mae: 3.0006 - val_loss: 18.0860 - val_mae: 3.4102\n",
      "Epoch 100/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 17.8425 - mae: 3.2050 - val_loss: 18.9506 - val_mae: 3.4506\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Actual_2022_Data.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/mac/Desktop/DataScience/deeplearning/Temperature-Prediction-Using-Neural-Networks/Comparaison.ipynb Cell 1\u001b[0m line \u001b[0;36m6\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mac/Desktop/DataScience/deeplearning/Temperature-Prediction-Using-Neural-Networks/Comparaison.ipynb#W0sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m \u001b[39m# Step 4: Load actual 2022 data and compare\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mac/Desktop/DataScience/deeplearning/Temperature-Prediction-Using-Neural-Networks/Comparaison.ipynb#W0sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m actual_data_path \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mActual_2022_Data.xlsx\u001b[39m\u001b[39m'\u001b[39m  \u001b[39m# Replace with the correct file path\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/mac/Desktop/DataScience/deeplearning/Temperature-Prediction-Using-Neural-Networks/Comparaison.ipynb#W0sZmlsZQ%3D%3D?line=67'>68</a>\u001b[0m actual_data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_excel(actual_data_path)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mac/Desktop/DataScience/deeplearning/Temperature-Prediction-Using-Neural-Networks/Comparaison.ipynb#W0sZmlsZQ%3D%3D?line=69'>70</a>\u001b[0m \u001b[39m# Ensure 'date' column is datetime and align data\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mac/Desktop/DataScience/deeplearning/Temperature-Prediction-Using-Neural-Networks/Comparaison.ipynb#W0sZmlsZQ%3D%3D?line=70'>71</a>\u001b[0m actual_data[\u001b[39m'\u001b[39m\u001b[39mdate\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mto_datetime(actual_data[\u001b[39m'\u001b[39m\u001b[39mdate\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/excel/_base.py:495\u001b[0m, in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[0m\n\u001b[1;32m    493\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(io, ExcelFile):\n\u001b[1;32m    494\u001b[0m     should_close \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m--> 495\u001b[0m     io \u001b[39m=\u001b[39m ExcelFile(\n\u001b[1;32m    496\u001b[0m         io,\n\u001b[1;32m    497\u001b[0m         storage_options\u001b[39m=\u001b[39mstorage_options,\n\u001b[1;32m    498\u001b[0m         engine\u001b[39m=\u001b[39mengine,\n\u001b[1;32m    499\u001b[0m         engine_kwargs\u001b[39m=\u001b[39mengine_kwargs,\n\u001b[1;32m    500\u001b[0m     )\n\u001b[1;32m    501\u001b[0m \u001b[39melif\u001b[39;00m engine \u001b[39mand\u001b[39;00m engine \u001b[39m!=\u001b[39m io\u001b[39m.\u001b[39mengine:\n\u001b[1;32m    502\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    503\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mEngine should not be specified when passing \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    504\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    505\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/excel/_base.py:1550\u001b[0m, in \u001b[0;36mExcelFile.__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[1;32m   1548\u001b[0m     ext \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxls\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1549\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1550\u001b[0m     ext \u001b[39m=\u001b[39m inspect_excel_format(\n\u001b[1;32m   1551\u001b[0m         content_or_path\u001b[39m=\u001b[39mpath_or_buffer, storage_options\u001b[39m=\u001b[39mstorage_options\n\u001b[1;32m   1552\u001b[0m     )\n\u001b[1;32m   1553\u001b[0m     \u001b[39mif\u001b[39;00m ext \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1554\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1555\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mExcel file format cannot be determined, you must specify \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1556\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39man engine manually.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1557\u001b[0m         )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/excel/_base.py:1402\u001b[0m, in \u001b[0;36minspect_excel_format\u001b[0;34m(content_or_path, storage_options)\u001b[0m\n\u001b[1;32m   1399\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(content_or_path, \u001b[39mbytes\u001b[39m):\n\u001b[1;32m   1400\u001b[0m     content_or_path \u001b[39m=\u001b[39m BytesIO(content_or_path)\n\u001b[0;32m-> 1402\u001b[0m \u001b[39mwith\u001b[39;00m get_handle(\n\u001b[1;32m   1403\u001b[0m     content_or_path, \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m, storage_options\u001b[39m=\u001b[39mstorage_options, is_text\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   1404\u001b[0m ) \u001b[39mas\u001b[39;00m handle:\n\u001b[1;32m   1405\u001b[0m     stream \u001b[39m=\u001b[39m handle\u001b[39m.\u001b[39mhandle\n\u001b[1;32m   1406\u001b[0m     stream\u001b[39m.\u001b[39mseek(\u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/common.py:882\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    873\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(\n\u001b[1;32m    874\u001b[0m             handle,\n\u001b[1;32m    875\u001b[0m             ioargs\u001b[39m.\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    878\u001b[0m             newline\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    879\u001b[0m         )\n\u001b[1;32m    880\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m--> 882\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n\u001b[1;32m    883\u001b[0m     handles\u001b[39m.\u001b[39mappend(handle)\n\u001b[1;32m    885\u001b[0m \u001b[39m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Actual_2022_Data.xlsx'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "\n",
    "# Step 1: Load and preprocess the 2021 data\n",
    "file_path = 'Marrakech Data 2021.xlsx'  # Replace with the correct file path\n",
    "data_df = pd.read_excel(file_path, sheet_name='Export')\n",
    "\n",
    "# Convert 'date' to datetime and create additional features\n",
    "data_df['date'] = pd.to_datetime(data_df['date'])\n",
    "data_df['day'] = data_df['date'].dt.day\n",
    "data_df['month'] = data_df['date'].dt.month\n",
    "data_df['weekday'] = data_df['date'].dt.weekday\n",
    "\n",
    "# Fill missing values for features\n",
    "features = ['day', 'month', 'weekday', 'prcp', 'wdir', 'wspd', 'pres']\n",
    "data_df[features] = data_df[features].fillna(data_df[features].median())\n",
    "\n",
    "# Prepare input features and target variable\n",
    "X = data_df[features]\n",
    "y = data_df['tavg']\n",
    "\n",
    "# Normalize features\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.1, random_state=42)\n",
    "\n",
    "# Step 2: Build and train the neural network\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dropout(0.2),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='linear')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, batch_size=32, verbose=1)\n",
    "\n",
    "# Step 3: Generate predictions for 2022\n",
    "future_dates = [datetime.date(2022, 1, 1) + datetime.timedelta(days=i) for i in range(365)]\n",
    "future_df = pd.DataFrame({\n",
    "    'date': future_dates,\n",
    "    'day': [d.day for d in future_dates],\n",
    "    'month': [d.month for d in future_dates],\n",
    "    'weekday': [d.weekday() for d in future_dates],\n",
    "    'prcp': np.random.uniform(data_df['prcp'].min(), data_df['prcp'].max(), len(future_dates)),\n",
    "    'wdir': np.random.uniform(data_df['wdir'].min(), data_df['wdir'].max(), len(future_dates)),\n",
    "    'wspd': np.random.uniform(data_df['wspd'].min(), data_df['wspd'].max(), len(future_dates)),\n",
    "    'pres': np.random.uniform(data_df['pres'].min(), data_df['pres'].max(), len(future_dates))\n",
    "})\n",
    "\n",
    "# Normalize future data and predict temperatures\n",
    "future_X = scaler.transform(future_df[features])\n",
    "future_predictions = model.predict(future_X)\n",
    "future_df['tavg_predicted'] = future_predictions\n",
    "\n",
    "# Step 4: Load actual 2022 data and compare\n",
    "actual_data_path = 'Marrakech_2022_Data.xlsx'  # Replace with the correct file path\n",
    "actual_data = pd.read_excel('Marrakech_2022_Data.xlsx')\n",
    "\n",
    "# Ensure 'date' column is datetime and align data\n",
    "actual_data['date'] = pd.to_datetime(actual_data['date'])\n",
    "merged_data = pd.merge(future_df[['date', 'tavg_predicted']], actual_data[['date', 'tavg']], on='date', suffixes=('_predicted', '_actual'))\n",
    "\n",
    "# Calculate accuracy metrics\n",
    "mae = mean_absolute_error(merged_data['tavg_actual'], merged_data['tavg_predicted'])\n",
    "mse = mean_squared_error(merged_data['tavg_actual'], merged_data['tavg_predicted'])\n",
    "r2 = r2_score(merged_data['tavg_actual'], merged_data['tavg_predicted'])\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
    "print(f\"R² Score: {r2:.2f}\")\n",
    "\n",
    "# Step 5: Plot the comparison\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(merged_data['date'], merged_data['tavg_actual'], label='Actual Temperature', color='blue', marker='o', linestyle='-', alpha=0.7)\n",
    "plt.plot(merged_data['date'], merged_data['tavg_predicted'], label='Predicted Temperature', color='orange', marker='x', linestyle='--', alpha=0.7)\n",
    "plt.title('Comparison of Actual vs Predicted Temperatures for 2022', fontsize=16)\n",
    "plt.xlabel('Date', fontsize=12)\n",
    "plt.ylabel('Temperature (°C)', fontsize=12)\n",
    "plt.legend(fontsize=12)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save the comparison results\n",
    "comparison_output_path = 'Comparison_2022.csv'\n",
    "merged_data.to_csv(comparison_output_path, index=False)\n",
    "print(f\"Comparison data saved to {comparison_output_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
